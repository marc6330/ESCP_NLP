{
 "cells": [
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import necessary modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## for data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import re\n",
    "\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for ML prep amd ML\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "import sklearn.metrics as sm\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading Data and sampling it to digestible format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('C:/Users/Marc/Dropbox/06_ESCP/01_Uni/04_Term 2/10_NLP with Python/02_Assingment 4&5/train_a4_5.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_test= pd.read_csv('C:/Users/Marc/Dropbox/06_ESCP/01_Uni/04_Term 2/10_NLP with Python/02_Assingment 4&5/test_a4_5.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# take the sample random rather then just the top 10000\n",
    "df_train_r = df_train.sample(n=10000, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking for and removing NaN in keywords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 3644682 to 2384596\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ID        10000 non-null  int64 \n",
      " 1   keywords  8828 non-null   object\n",
      " 2   age       10000 non-null  int64 \n",
      " 3   sex       10000 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 390.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking how many NaN there are, then dropping\n",
    "df_train_r.info()\n",
    "df_train_r = df_train_r.dropna(subset=['keywords'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Verifying if NaN are reduced\n",
    "df_train_r.info()\n",
    "# Sex and age given, question what to do with the ngrams\n",
    "# -> tokenization has already happened, lemmatization could still be done, stopwords?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8828 entries, 3644682 to 2384596\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ID        8828 non-null   int64 \n",
      " 1   keywords  8828 non-null   object\n",
      " 2   age       8828 non-null   int64 \n",
      " 3   sex       8828 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 344.8+ KB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rename DF and features for comprehensiveness\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_train_r['sex'].replace('M', 1, inplace = True)\n",
    "df_train_r['sex'].replace('F', 0, inplace = True)\n",
    "dtf = df_train_r.rename(columns = {'keywords': 'text', 'sex': 'y'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8828 entries, 3644682 to 2384596\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      8828 non-null   int64 \n",
      " 1   text    8828 non-null   object\n",
      " 2   age     8828 non-null   int64 \n",
      " 3   y       8828 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 344.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dtf.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See distribution for features: 'Age'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dtf.age, bins = 20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#clean stopwords out of list\n",
    "final_stopwords_list = list(fr_stop)\n",
    "\n",
    "dtf['text'] = [i.replace(\":\", \"':\") for i in dtf.text]\n",
    "dtf['text'] = [i.replace(\";\", \",'\") for i in dtf.text]\n",
    "dtf['text'] = [\"{'\" + i + \"}\" for i in dtf.text]\n",
    "dtf['text'] = [literal_eval(i) for i in dtf.text]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[1;36m(most recent call last)\u001B[0m:\n",
      "  File \u001B[0;32m\"c:\\users\\marc\\documents\\github\\02_python\\02_assingment nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001B[0m, line \u001B[0;32m3441\u001B[0m, in \u001B[0;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001B[0;32m\"<ipython-input-23-d3d1f4dfe13e>\"\u001B[0m, line \u001B[0;32m7\u001B[0m, in \u001B[0;35m<module>\u001B[0m\n    dtf['text'] = [literal_eval(i) for i in dtf.text]\n",
      "  File \u001B[0;32m\"<ipython-input-23-d3d1f4dfe13e>\"\u001B[0m, line \u001B[0;32m7\u001B[0m, in \u001B[0;35m<listcomp>\u001B[0m\n    dtf['text'] = [literal_eval(i) for i in dtf.text]\n",
      "  File \u001B[0;32m\"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\ast.py\"\u001B[0m, line \u001B[0;32m59\u001B[0m, in \u001B[0;35mliteral_eval\u001B[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\ast.py\"\u001B[1;36m, line \u001B[1;32m47\u001B[1;36m, in \u001B[1;35mparse\u001B[1;36m\u001B[0m\n\u001B[1;33m    return compile(source, filename, mode, flags,\u001B[0m\n",
      "\u001B[1;36m  File \u001B[1;32m\"<unknown>\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    {'{'pratique'':4,'management'':4,'divers'':4,'bail'':4,'commercial'':4}}\u001B[0m\n\u001B[1;37m        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_cleaned = []\n",
    "\n",
    "for dict in dtf.text:\n",
    "    for word in final_stopwords_list:\n",
    "        if word in dict:\n",
    "            del dict[word]\n",
    "    text_cleaned.append(dict)\n",
    "\n",
    "dtf['text_cleaned'] = text_cleaned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item deletion",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-22-1c8b873dc879>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mword\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfinal_stopwords_list\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mword\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m             \u001B[1;32mdel\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m     \u001B[0mtext_cleaned\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'str' object does not support item deletion"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dtf['text_cleaned'] = [str(i).replace(\"':\", \":\") for i in dtf.text_cleaned]\n",
    "dtf['text_cleaned'] = [str(i).replace(\",'\", \";\") for i in dtf.text_cleaned]\n",
    "dtf['text_cleaned'] = [str(i).replace(\"{\", \"\") for i in dtf.text_cleaned]\n",
    "dtf['text_cleaned'] = [str(i).replace(\"}\", \"\") for i in dtf.text_cleaned]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NLP - create feature matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating the feature matrix\n",
    "matrix = CountVectorizer(max_features=2000)\n",
    "X = matrix.fit_transform(dtf.text_cleaned).toarray()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Age Predicition\n",
    "\n",
    "Linear Model (Lasso)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_reg = df_train_r.age"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_r, y_test_r = train_test_split(X, y_reg)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "linreg = LinearRegression()\n",
    "\n",
    "linreg.fit(X_train, y_train_r)\n",
    "\n",
    "# Predict Class\n",
    "y_pred_linreg = np.round(linreg.predict(X_test))\n",
    "\n",
    "# Metrics\n",
    "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test_r, y_pred_linreg), 2))\n",
    "print(\"Mean squared error =\", round(sm.mean_squared_error(y_test_r, y_pred_linreg), 2))\n",
    "print(\"Median absolute error =\", round(sm.median_absolute_error(y_test_r, y_pred_linreg), 2))\n",
    "print(\"Explain variance score =\", round(sm.explained_variance_score(y_test_r, y_pred_linreg), 2))\n",
    "print(\"R2 score =\", round(sm.r2_score(y_test_r, y_pred_linreg), 2))\n",
    "\n",
    "\n",
    "#check output\n",
    "plt.hist(y_pred_linreg, bins = 20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Problem that linear_model predicts 46 for everyone"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ert = pd.DataFrame(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RF Regression\n",
    "rfreg = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "rfreg.fit(X_train, y_train_r)\n",
    "\n",
    "# Predict Class\n",
    "y_pred_rfreg = np.round(rfreg.predict(X_test))\n",
    "\n",
    "# Metrics\n",
    "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test_r, y_pred_rfreg), 2))\n",
    "print(\"Mean squared error =\", round(sm.mean_squared_error(y_test_r, y_pred_rfreg), 2))\n",
    "print(\"Median absolute error =\", round(sm.median_absolute_error(y_test_r, y_pred_rfreg), 2))\n",
    "print(\"Explain variance score =\", round(sm.explained_variance_score(y_test_r, y_pred_rfreg), 2))\n",
    "print(\"R2 score =\", round(sm.r2_score(y_test_r, y_pred_rfreg), 2))\n",
    "\n",
    "\n",
    "#check output\n",
    "plt.hist(y_pred_rfreg, bins = 20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# XGBoost Regression\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "xgreg = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "xgreg.fit(X_train, y_train_r)\n",
    "\n",
    "# Predict Class\n",
    "y_pred_xgreg = np.round(xgreg.predict(X_test))\n",
    "\n",
    "# Metrics\n",
    "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test_r, y_pred_xgreg), 2))\n",
    "print(\"Mean squared error =\", round(sm.mean_squared_error(y_test_r, y_pred_xgreg), 2))\n",
    "print(\"Median absolute error =\", round(sm.median_absolute_error(y_test_r, y_pred_xgreg), 2))\n",
    "print(\"Explain variance score =\", round(sm.explained_variance_score(y_test_r, y_pred_xgreg), 2))\n",
    "print(\"R2 score =\", round(sm.r2_score(y_test_r, y_pred_xgreg), 2))\n",
    "\n",
    "\n",
    "#check output\n",
    "plt.hist(y_pred_xgreg, bins = 20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check solution\n",
    "plt.hist(y_test_r, bins = 20)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "by cleaning the dataset we might achieve mbetter results, however as we are not using acutual sentiment anaylsis, but only bog owords, even weird words could lead to the right age - sex.\n",
    " - Cleaning?\n",
    "    -  if yes how?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sex predicition\n",
    "\n",
    "\n",
    "dtf.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See distribution for features: 'Sex'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle(\"Number F / M\", fontsize=12)\n",
    "dtf[\"y\"].reset_index().groupby(\"y\").count().sort_values(by=\n",
    "       \"index\").plot(kind=\"barh\", legend=False,\n",
    "        ax=ax).grid(axis='x')\n",
    "plt.show()\n",
    "\n",
    "# Difference between occurance seems fair"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bag of Words appraoch:\n",
    "- reasonable as already word frequency shown in dataset\n",
    "- Q?:\n",
    "    - lemmatizationand stop word removals already done - Think yes\n",
    "    - tf-idf with max length 10k --> vocab 10k long - where as classic BoW already in Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NLP - create feature matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating the feature matrix\n",
    "matrix = CountVectorizer(max_features=2000)\n",
    "X = matrix.fit_transform(dtf.text).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = dtf.y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sex Predicition (1 =  M, 0 = F)\n",
    "\n",
    "Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "# Confusion Matrix\n",
    "plot_confusion_matrix(gnb, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_gnb))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression(random_state = 42, solver='liblinear')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# Confusion Matrix\n",
    "plot_confusion_matrix(lr, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}